{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"name":"dataset_merge.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"ej9bxb_ytgqs"},"source":["# Install any package dependencies\n","# !pip install datasets\n","\n","# Import any required libraries\n","from datasets import load_dataset\n","from google.colab import drive\n","import os\n","\n","# IF NEWS ROOM IS NOT CACHED YET, use the following link to request the full dataset: https://cornell.qualtrics.com/jfe/form/SV_6YA3HQ2p75XH4IR\n","# You will receive an email to download the dataset. Download, unzip, and uncompress the files from google drive \n","# replace the filepath below if needed to store the dataset in the huggingface cache \n","\n","# # Use google drive to store initial dataset before caching (if required by the dataset):\n","# drive.mount('/content/drive')\n","# # Load dataset and store in cache:\n","# ds = load_dataset('newsroom', split='test', data_dir='/content/drive/My Drive/newsroom')\n","\n","# load all other datasets here...\n","newsroom = load_dataset('newsroom', split='train')\n","arxiv = load_dataset('scientific_papers', 'arxiv', split='train')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qNqQp1lKtgqw"},"source":["# Use this dictionary to store the keys used to acces summary/text in each dataset\n","# This is to account for different naming conventions between the datasets we use\n","\n","dataset_keys = {\n","    'newsroom': {\n","        'DATASET_OBJ': ds,\n","        'TEXT': 'text',\n","        'SMRY': 'summary'\n","    },\n","    'arXiv': {\n","        # ... fill in the rest\n","    } # ...add all other datasets\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2B9kY3lNtgq1"},"source":["def make_dataset_string(split='train', demo_mode=True):\n","  assert split in ['train', 'test']\n","  # Change <demo_mode> to False if you want to process each ENTIRE dataset \n","\n","  if demo_mode:\n","      print('DEMO MODE ACTIVE\\n\\n')\n","\n","  # Currently, this code will store the processed datasets as a list of entries \n","  # Each entry is stored as a processed string in the form of:\n","  # [TEXT]\n","  # blah blah\n","  # ...\n","  # blah blah\n","  # [SMRY]\n","  # blah blah\n","  # \n","  # <START OVER AGAIN>  --> This line is not in the string \n","  #                     --> indicates how formatting would look if the entries were concatenated\n","  #                     --> entries DO CONTAIN THEIR OWN NEWLINES\n","\n","  processed_datasets = { }\n","\n","  for name in dataset_dict_keys.keys():\n","      # access respective keys to account for naming conventions\n","      ds_keys = dataset_keys[name]\n","      ds_obj = ds_keys['DATASET_OBJ']\n","      \n","      processed_entries = []\n","      for index, entry in enumerate(ds_obj):\n","          # Get text and prepare for processing\n","          text = entry[ds_keys['TEXT']]\n","          smry = entry[ds_keys['SMRY']]\n","          assert type(text) == str and type(smry) == str\n","          # concatenate break indicators and actual text/summaries\n","          processed_entries.append(''.join(['[TEXT]\\n', text, '\\n[SMRY]\\n', smry, '\\n\\n']))\n","          if not index % 1000:\n","              print('Processing Dataset \\\"%s\\\" at Index %d' % (name, index))\n","              if demo_mode and index == 2000:\n","                  break\n","      print('\\nFINISHED Processing Dataset \\\"%s\\\"\\n' % name)\n","      processed_datasets[name] = processed_entries\n","\n","  return processed_datasets\n","\n","# To combine one dataset into a single string for training/testing, use the following:\n","# ''.join(processed_datasets[<name_of_dataset>])\n","# To combine the entire dictionary of datasets into a single string, use the following:\n","# ''.join([''.join(processed_datasets[name]) for name in processed_datasets.keys()])\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NMZLiy0Xtgq3","executionInfo":{"status":"ok","timestamp":1602447499719,"user_tz":300,"elapsed":4047,"user":{"displayName":"Neil Kaushikkar","photoUrl":"","userId":"04245653301361239178"}},"outputId":"925cfc77-e96d-4e94-e0ce-434c7e39d8fe","colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["# Configure Drive/Colab/GitHub Here\n","# Use notes in text cell below if needed\n","\n","from google.colab import drive\n","from getpass import getpass\n","import os\n","%cd '/content/drive/My Drive/CS196Project/Group6'\n","\n","uname = \"nkaush\"\n","!git config --global user.email '$neil.kaushikkar@gmail.com'\n","!git config --global user.name '$uname'\n","# password = getpass('Password:')\n","\n"],"execution_count":24,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/CS196Project/Group6\n","[neilk3 e0966fb] Reconfigured notebook with access to the GitHub repo\n"," 1 file changed, 1 insertion(+), 1 deletion(-)\n","Counting objects: 6, done.\n","Delta compression using up to 2 threads.\n","Compressing objects: 100% (6/6), done.\n","Writing objects: 100% (6/6), 2.99 KiB | 766.00 KiB/s, done.\n","Total 6 (delta 3), reused 0 (delta 0)\n","remote: Resolving deltas: 100% (3/3), completed with 1 local object.\u001b[K\n","To https://github.com/CS196Illinois/Group6.git\n","   efc197b..e0966fb  neilk3 -> neilk3\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LuVtkzyxUL1v"},"source":["Step 1: Prepare Drive/Colab:\n","```\n","from google.colab import drive\n","drive.mount('/content/drive')\n","%cd '/content/drive/My Drive/<desired path to project>'\n","```\n","Step 2: Clone GitHub Repo in Drive:\n","```\n","uname = \"<username>\"\n","!git config --global user.email '$<someone>@<email>.com'\n","!git config --global user.name '$uname'\n","password = getpass('Password:')\n","\n","!git clone https://$uname:$password@github.com/CS196Illinois/Group6\n","%cd Group6\n","```\n","Step 3: Add, Commit, Push, etc...:\n","```\n","!git add <file>\n","!git commit -m 'commit message'\n","!git push origin <branch>\n","```\n","[OPTIONAL] Step 4: If Authentication Fails:\n","```\n","git remote -v \n","git remote remove origin \n","git remote add origin https://$uname:$password@github.com/CS196Illinois/Group6.git\n","```\n","Notes Compiled From:\n","- [Push from Colab to GitHub](https://stackoverflow.com/questions/59454990/how-to-push-from-colab-to-github)\n","\n","- [Git Push Authentication Failed](https://stackoverflow.com/questions/17659206/git-push-results-in-authentication-failed)\n"]}]}