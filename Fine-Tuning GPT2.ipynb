{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Fine-Tuning GPT2.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"QWmtbdYHI9HN"},"source":["# Fine-Tuning GPT2 on Colab GPU… For Free!\n","\n","This is a colab notebook for the [associated Medium article](https://medium.com/p/340468c92ed)"]},{"cell_type":"markdown","metadata":{"id":"1ov2wQbRIs8J"},"source":["## Installing Dependencies\n","We would run pip3 install transformers normally in Bash, but because this is in Colab, we have to run it with !"]},{"cell_type":"code","metadata":{"id":"GVQ5Le5kF7CV","executionInfo":{"status":"ok","timestamp":1603569791095,"user_tz":300,"elapsed":12674,"user":{"displayName":"Neil Kaushikkar","photoUrl":"","userId":"04245653301361239178"}},"outputId":"efe71900-977f-4176-e196-097d38f27c62","colab":{"base_uri":"https://localhost:8080/","height":581}},"source":["# !pip3 install transformers\n","!python -m pip install git+https://github.com/huggingface/transformers.git"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Collecting git+https://github.com/huggingface/transformers.git\n","  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-291usg2k\n","  Running command git clone -q https://github.com/huggingface/transformers.git /tmp/pip-req-build-291usg2k\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied (use --upgrade to upgrade): transformers==3.4.0 from git+https://github.com/huggingface/transformers.git in /usr/local/lib/python3.6/dist-packages\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (3.0.12)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (2019.12.20)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (20.4)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (0.7)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (3.12.4)\n","Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (0.1.94)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (0.0.43)\n","Requirement already satisfied: tokenizers==0.9.2 in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (0.9.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (1.18.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (4.41.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.4.0) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.4.0) (1.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers==3.4.0) (50.3.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.4.0) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.4.0) (0.16.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.4.0) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.4.0) (2020.6.20)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.4.0) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.4.0) (3.0.4)\n","Building wheels for collected packages: transformers\n","  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for transformers: filename=transformers-3.4.0-cp36-none-any.whl size=1275545 sha256=0de7fc7e37d43cfab7a9e0fe8a92f8e642015b8d7617294d8e43781fc8cba474\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-1bq_jb7z/wheels/33/eb/3b/4bf5dd835e865e472d4fc0754f35ac0edb08fe852e8f21655f\n","Successfully built transformers\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Wdfc4qUVKYLj"},"source":["## Getting WikiText Data\n","\n","You can read more about WikiText data here. Overall, there's WikiText-2 and WikiText-103. We're going to use WikiText-2 because it's smaller, and we have limits in terms of how long we can run on GPU, and how much data we can load into memory in Colab. To download and run"]},{"cell_type":"code","metadata":{"id":"C4RMT_FQIrGi","executionInfo":{"status":"ok","timestamp":1603568901048,"user_tz":300,"elapsed":1249,"user":{"displayName":"Neil Kaushikkar","photoUrl":"","userId":"04245653301361239178"}},"outputId":"81a6ecdf-33cf-4feb-db78-a242fd200276","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["%%bash\n","wget https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-2-raw-v1.zip\n","unzip wikitext-2-raw-v1.zip"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Archive:  wikitext-2-raw-v1.zip\n"],"name":"stdout"},{"output_type":"stream","text":["--2020-10-24 19:48:20--  https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-2-raw-v1.zip\n","Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.16.14\n","Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.16.14|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 4721645 (4.5M) [application/zip]\n","Saving to: ‘wikitext-2-raw-v1.zip.1’\n","\n","     0K .......... .......... .......... .......... ..........  1%  814K 6s\n","    50K .......... .......... .......... .......... ..........  2%  812K 6s\n","   100K .......... .......... .......... .......... ..........  3%  818K 5s\n","   150K .......... .......... .......... .......... ..........  4% 43.4M 4s\n","   200K .......... .......... .......... .......... ..........  5%  830K 4s\n","   250K .......... .......... .......... .......... ..........  6% 91.7M 4s\n","   300K .......... .......... .......... .......... ..........  7% 71.6M 3s\n","   350K .......... .......... .......... .......... ..........  8%  143M 3s\n","   400K .......... .......... .......... .......... ..........  9%  832K 3s\n","   450K .......... .......... .......... .......... .......... 10%  235M 3s\n","   500K .......... .......... .......... .......... .......... 11%  197M 2s\n","   550K .......... .......... .......... .......... .......... 13% 92.5M 2s\n","   600K .......... .......... .......... .......... .......... 14%  130M 2s\n","   650K .......... .......... .......... .......... .......... 15%  113M 2s\n","   700K .......... .......... .......... .......... .......... 16% 91.5M 2s\n","   750K .......... .......... .......... .......... .......... 17%  120M 1s\n","   800K .......... .......... .......... .......... .......... 18%  853K 2s\n","   850K .......... .......... .......... .......... .......... 19%  205M 2s\n","   900K .......... .......... .......... .......... .......... 20%  244M 1s\n","   950K .......... .......... .......... .......... .......... 21%  207M 1s\n","  1000K .......... .......... .......... .......... .......... 22%  151M 1s\n","  1050K .......... .......... .......... .......... .......... 23%  207M 1s\n","  1100K .......... .......... .......... .......... .......... 24%  110M 1s\n","  1150K .......... .......... .......... .......... .......... 26%  154M 1s\n","  1200K .......... .......... .......... .......... .......... 27%  217M 1s\n","  1250K .......... .......... .......... .......... .......... 28%  227M 1s\n","  1300K .......... .......... .......... .......... .......... 29%  144M 1s\n","  1350K .......... .......... .......... .......... .......... 30%  173M 1s\n","  1400K .......... .......... .......... .......... .......... 31%  202M 1s\n","  1450K .......... .......... .......... .......... .......... 32%  167M 1s\n","  1500K .......... .......... .......... .......... .......... 33%  178M 1s\n","  1550K .......... .......... .......... .......... .......... 34%  174M 1s\n","  1600K .......... .......... .......... .......... .......... 35%  180M 1s\n","  1650K .......... .......... .......... .......... .......... 36%  222M 1s\n","  1700K .......... .......... .......... .......... .......... 37%  879K 1s\n","  1750K .......... .......... .......... .......... .......... 39%  253M 1s\n","  1800K .......... .......... .......... .......... .......... 40%  241M 1s\n","  1850K .......... .......... .......... .......... .......... 41%  177M 1s\n","  1900K .......... .......... .......... .......... .......... 42%  210M 1s\n","  1950K .......... .......... .......... .......... .......... 43%  190M 1s\n","  2000K .......... .......... .......... .......... .......... 44%  208M 1s\n","  2050K .......... .......... .......... .......... .......... 45%  153M 1s\n","  2100K .......... .......... .......... .......... .......... 46%  172M 0s\n","  2150K .......... .......... .......... .......... .......... 47%  212M 0s\n","  2200K .......... .......... .......... .......... .......... 48%  218M 0s\n","  2250K .......... .......... .......... .......... .......... 49%  193M 0s\n","  2300K .......... .......... .......... .......... .......... 50%  222M 0s\n","  2350K .......... .......... .......... .......... .......... 52%  235M 0s\n","  2400K .......... .......... .......... .......... .......... 53%  216M 0s\n","  2450K .......... .......... .......... .......... .......... 54%  177M 0s\n","  2500K .......... .......... .......... .......... .......... 55%  218M 0s\n","  2550K .......... .......... .......... .......... .......... 56%  218M 0s\n","  2600K .......... .......... .......... .......... .......... 57%  207M 0s\n","  2650K .......... .......... .......... .......... .......... 58%  203M 0s\n","  2700K .......... .......... .......... .......... .......... 59%  238M 0s\n","  2750K .......... .......... .......... .......... .......... 60%  228M 0s\n","  2800K .......... .......... .......... .......... .......... 61%  220M 0s\n","  2850K .......... .......... .......... .......... .......... 62%  211M 0s\n","  2900K .......... .......... .......... .......... .......... 63%  259M 0s\n","  2950K .......... .......... .......... .......... .......... 65%  260M 0s\n","  3000K .......... .......... .......... .......... .......... 66%  266M 0s\n","  3050K .......... .......... .......... .......... .......... 67%  246M 0s\n","  3100K .......... .......... .......... .......... .......... 68%  252M 0s\n","  3150K .......... .......... .......... .......... .......... 69%  251M 0s\n","  3200K .......... .......... .......... .......... .......... 70%  258M 0s\n","  3250K .......... .......... .......... .......... .......... 71%  218M 0s\n","  3300K .......... .......... .......... .......... .......... 72%  268M 0s\n","  3350K .......... .......... .......... .......... .......... 73%  260M 0s\n","  3400K .......... .......... .......... .......... .......... 74%  243M 0s\n","  3450K .......... .......... .......... .......... .......... 75%  923K 0s\n","  3500K .......... .......... .......... .......... .......... 76%  235M 0s\n","  3550K .......... .......... .......... .......... .......... 78%  249M 0s\n","  3600K .......... .......... .......... .......... .......... 79%  194M 0s\n","  3650K .......... .......... .......... .......... .......... 80%  173M 0s\n","  3700K .......... .......... .......... .......... .......... 81%  251M 0s\n","  3750K .......... .......... .......... .......... .......... 82%  259M 0s\n","  3800K .......... .......... .......... .......... .......... 83%  265M 0s\n","  3850K .......... .......... .......... .......... .......... 84% 53.0M 0s\n","  3900K .......... .......... .......... .......... .......... 85%  217M 0s\n","  3950K .......... .......... .......... .......... .......... 86%  200M 0s\n","  4000K .......... .......... .......... .......... .......... 87%  231M 0s\n","  4050K .......... .......... .......... .......... .......... 88%  174M 0s\n","  4100K .......... .......... .......... .......... .......... 90%  215M 0s\n","  4150K .......... .......... .......... .......... .......... 91%  219M 0s\n","  4200K .......... .......... .......... .......... .......... 92%  236M 0s\n","  4250K .......... .......... .......... .......... .......... 93%  237M 0s\n","  4300K .......... .......... .......... .......... .......... 94%  274M 0s\n","  4350K .......... .......... .......... .......... .......... 95%  256M 0s\n","  4400K .......... .......... .......... .......... .......... 96%  253M 0s\n","  4450K .......... .......... .......... .......... .......... 97%  213M 0s\n","  4500K .......... .......... .......... .......... .......... 98%  263M 0s\n","  4550K .......... .......... .......... .......... .......... 99%  268M 0s\n","  4600K ..........                                            100%  190M=0.5s\n","\n","2020-10-24 19:48:20 (9.06 MB/s) - ‘wikitext-2-raw-v1.zip.1’ saved [4721645/4721645]\n","\n","replace wikitext-2-raw/wiki.test.raw? [y]es, [n]o, [A]ll, [N]one, [r]ename:  NULL\n","(EOF or read error, treating as \"[N]one\" ...)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"lEJjg5wkLXgI"},"source":["## Fine-Tuning GPT2\n","\n","HuggingFace actually provides a script to help fine tune models here. We can just download the script by running"]},{"cell_type":"code","metadata":{"id":"E-L4LiHiKdr1","executionInfo":{"status":"ok","timestamp":1603568931669,"user_tz":300,"elapsed":671,"user":{"displayName":"Neil Kaushikkar","photoUrl":"","userId":"04245653301361239178"}},"outputId":"8340ba8f-f254-4332-cfb8-32403fa1677c","colab":{"base_uri":"https://localhost:8080/","height":224}},"source":["! wget https://raw.githubusercontent.com/huggingface/transformers/master/examples/language-modeling/run_language_modeling.py"],"execution_count":4,"outputs":[{"output_type":"stream","text":["--2020-10-24 19:48:51--  https://raw.githubusercontent.com/huggingface/transformers/master/examples/language-modeling/run_language_modeling.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 13076 (13K) [text/plain]\n","Saving to: ‘run_language_modeling.py’\n","\n","\rrun_language_modeli   0%[                    ]       0  --.-KB/s               \rrun_language_modeli 100%[===================>]  12.77K  --.-KB/s    in 0s      \n","\n","2020-10-24 19:48:51 (138 MB/s) - ‘run_language_modeling.py’ saved [13076/13076]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sklH4LNoMxRC"},"source":["Now we are ready to fine tune.\n","\n","There are many parameters to the script, and you can understand them by reading the manual. I'm just going to go over the important ones for basic training.\n","\n","- `output_dir` is where the model will be output\n","- `model_type` is what model you want to use. In our case, it's gpt2 \n","- `model_name_or_path` is the path to the model. If you want to train from scratch, you can leave this blank. In our case, it's also gpt2 \n","- `do_train` tells it to train\n","- `train_data_file` points to the training file\n","- `do_eval` tells it to evaluate afterwards. Not always required, but good to have\n","- `eval_data_file` points to the evaluation file\n","\n","Some extra ones you MAY care about, but you can also skip this.\n","- `save_steps` is when to save checkpoints. If you have limited memory, you can set this to -1 so it'll skip saving until the end\n","- `per_gpu_train_batch_size` is batch size for GPU. You can increase this if your GPU has enough memory. To be safe, you can start with 1 and ramp it up if you still have memory\n","- `num_train_epochs` is the number of epochs to train. Since we're fine-tuning, I'm going to set this to 2\n"]},{"cell_type":"code","metadata":{"id":"e74yVH7QV5t9","executionInfo":{"status":"ok","timestamp":1603571115530,"user_tz":300,"elapsed":16686,"user":{"displayName":"Neil Kaushikkar","photoUrl":"","userId":"04245653301361239178"}},"outputId":"c52b56ec-c076-4c45-efe0-3df15b40661b","colab":{"base_uri":"https://localhost:8080/","height":564}},"source":["# Install any package dependencies\n","!pip install datasets\n","\n","# Import any required libraries\n","from datasets import load_dataset\n","from google.colab import drive\n","import os\n","\n","# Use google drive to store initial dataset before caching (if required by the dataset):\n","drive.mount('/content/drive')\n","\n","# load all other datasets here...\n","newsroom = load_dataset('newsroom', split='train', data_dir='/content/drive/My Drive/newsroom')\n","newsroom_test = load_dataset('newsroom', split='test', data_dir='/content/drive/My Drive/newsroom')\n","dataset_keys = {\n","  'newsroom_train': {\n","    'DATASET_OBJ': newsroom,\n","    'TEXT': 'text',\n","    'SMRY': 'summary'\n","  },\n","  'newsroom_test': {\n","    'DATASET_OBJ': newsroom_test,\n","    'TEXT': 'text',\n","    'SMRY': 'summary'\n","  }\n","}\n","\n","\n","def make_dataset_file(split='train', demo_mode=False):\n","  assert split in ['train', 'test']\n","  # Change <demo_mode> to False if you want to process each ENTIRE dataset \n","\n","  if demo_mode:\n","      print('DEMO MODE ACTIVE\\n\\n')\n","\n","  processed_datasets = { }\n","\n","  for name in dataset_keys.keys():\n","      # access respective keys to account for naming conventions\n","      ds_keys = dataset_keys[name]\n","      ds_obj = ds_keys['DATASET_OBJ']\n","      \n","      f = open('%s.txt' % name, 'w+')\n","      for index, entry in enumerate(ds_obj):\n","          # Get text and prepare for processing\n","          text = entry[ds_keys['TEXT']]\n","          text = ''.join(text.split(\"\\n\"))\n","          smry = entry[ds_keys['SMRY']]\n","          assert type(text) == str and type(smry) == str\n","          # concatenate break indicators and actual text/summaries\n","          f.write(''.join(['[TEXT]\\n', text, '\\n[SUMM]\\n', smry, '[SEP]\\n\\n']))\n","          if index > 200:\n","            break\n","          if not index % 100000:\n","              print('Processing Dataset \\\"%s\\\" at Index %d' % (name, index))\n","              if demo_mode and index == 2000:\n","                  break\n","      print('\\nFINISHED Processing Dataset \\\"%s\\\"\\n' % name)\n","      f.close()\n","\n","make_dataset_file()"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: datasets in /usr/local/lib/python3.6/dist-packages (1.1.2)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from datasets) (3.0.12)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.6/dist-packages (from datasets) (2.0.0)\n","Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.6/dist-packages (from datasets) (4.41.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from datasets) (1.18.5)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from datasets) (0.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from datasets) (1.1.2)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.6/dist-packages (from datasets) (0.70.10)\n","Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from datasets) (0.3.2)\n","Requirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from datasets) (2.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (2020.6.20)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->datasets) (2.8.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->datasets) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"},{"output_type":"stream","text":["Using custom data configuration default\n","Reusing dataset newsroom (/root/.cache/huggingface/datasets/newsroom/default/1.0.0/4b405ccd64e15f685065870ea563a1e6a034d1bd269a5427f40146d81549095e)\n","Using custom data configuration default\n","Reusing dataset newsroom (/root/.cache/huggingface/datasets/newsroom/default/1.0.0/4b405ccd64e15f685065870ea563a1e6a034d1bd269a5427f40146d81549095e)\n"],"name":"stderr"},{"output_type":"stream","text":["Processing Dataset \"newsroom_train\" at Index 0\n","\n","FINISHED Processing Dataset \"newsroom_train\"\n","\n","Processing Dataset \"newsroom_test\" at Index 0\n","\n","FINISHED Processing Dataset \"newsroom_test\"\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Y6fspISiMx5V","executionInfo":{"status":"ok","timestamp":1603570749391,"user_tz":300,"elapsed":216966,"user":{"displayName":"Neil Kaushikkar","photoUrl":"","userId":"04245653301361239178"}},"outputId":"a87d3a73-1283-4b84-cfe4-6e2676055f23","colab":{"base_uri":"https://localhost:8080/","height":428}},"source":["%%bash\n","export TRAIN_FILE=newsroom_train.txt\n","export TEST_FILE=newsroom_test.txt\n","export MODEL_NAME=\"yuvraj/summarizer-cnndm\"\n","export OUTPUT_DIR=output_mine\n","\n","python run_language_modeling.py \\\n","    --output_dir=$OUTPUT_DIR \\\n","    --model_type=$MODEL_NAME \\\n","    --model_name_or_path=$MODEL_NAME \\\n","    --do_train \\\n","    --train_data_file=$TRAIN_FILE \\\n","    --do_eval \\\n","    --eval_data_file=$TEST_FILE \\\n","    --per_gpu_train_batch_size=1 \\\n","    --save_steps=-1 \\\n","    --num_train_epochs=2 \\\n"],"execution_count":23,"outputs":[{"output_type":"stream","text":["2020-10-24 20:15:33.623236: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","10/24/2020 20:15:35 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False\n","10/24/2020 20:15:35 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='output_mine', overwrite_output_dir=False, do_train=True, do_eval=True, do_predict=False, evaluate_during_training=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=8, per_device_eval_batch_size=8, per_gpu_train_batch_size=1, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=2.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Oct24_20-15-35_6c1e22b6e772', logging_first_step=False, logging_steps=500, save_steps=-1, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='output_mine', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None)\n","/usr/local/lib/python3.6/dist-packages/transformers/modeling_auto.py:825: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n","  FutureWarning,\n","/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1374: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n","  FutureWarning,\n","10/24/2020 20:15:42 - INFO - filelock -   Lock 140567029244200 acquired on cached_lm_BartTokenizer_1022_newsroom_train.txt.lock\n","10/24/2020 20:15:43 - INFO - filelock -   Lock 140567029244200 released on cached_lm_BartTokenizer_1022_newsroom_train.txt.lock\n","10/24/2020 20:15:43 - INFO - filelock -   Lock 140567010517512 acquired on cached_lm_BartTokenizer_1022_newsroom_test.txt.lock\n","10/24/2020 20:15:44 - INFO - filelock -   Lock 140567010517512 released on cached_lm_BartTokenizer_1022_newsroom_test.txt.lock\n","/usr/local/lib/python3.6/dist-packages/transformers/trainer.py:263: FutureWarning: Passing `prediction_loss_only` as a keyword argument is deprecated and won't be possible in a future version. Use `args.prediction_loss_only` instead. Setting `args.prediction_loss_only=True\n","  FutureWarning,\n","Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n","Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n","Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n","\r  0%|          | 0/378 [00:00<?, ?it/s]\r  0%|          | 1/378 [00:00<04:24,  1.42it/s]\r  1%|          | 2/378 [00:01<03:50,  1.63it/s]\r  1%|          | 3/378 [00:01<03:26,  1.82it/s]\r  1%|          | 4/378 [00:01<03:11,  1.95it/s]\r  1%|▏         | 5/378 [00:02<02:59,  2.08it/s]\r  2%|▏         | 6/378 [00:02<02:50,  2.18it/s]\r  2%|▏         | 7/378 [00:03<02:45,  2.24it/s]\r  2%|▏         | 8/378 [00:03<02:40,  2.30it/s]\r  2%|▏         | 9/378 [00:03<02:37,  2.34it/s]\r  3%|▎         | 10/378 [00:04<02:35,  2.37it/s]\r  3%|▎         | 11/378 [00:04<02:34,  2.38it/s]\r  3%|▎         | 12/378 [00:05<02:32,  2.39it/s]\r  3%|▎         | 13/378 [00:05<02:31,  2.41it/s]\r  4%|▎         | 14/378 [00:06<02:31,  2.41it/s]\r  4%|▍         | 15/378 [00:06<02:30,  2.42it/s]\r  4%|▍         | 16/378 [00:06<02:29,  2.42it/s]\r  4%|▍         | 17/378 [00:07<02:29,  2.42it/s]\r  5%|▍         | 18/378 [00:07<02:28,  2.43it/s]\r  5%|▌         | 19/378 [00:08<02:27,  2.43it/s]\r  5%|▌         | 20/378 [00:08<02:28,  2.42it/s]\r  6%|▌         | 21/378 [00:08<02:27,  2.42it/s]\r  6%|▌         | 22/378 [00:09<02:26,  2.43it/s]\r  6%|▌         | 23/378 [00:09<02:26,  2.42it/s]\r  6%|▋         | 24/378 [00:10<02:26,  2.41it/s]\r  7%|▋         | 25/378 [00:10<02:26,  2.41it/s]\r  7%|▋         | 26/378 [00:11<02:26,  2.41it/s]\r  7%|▋         | 27/378 [00:11<02:25,  2.40it/s]\r  7%|▋         | 28/378 [00:11<02:25,  2.41it/s]\r  8%|▊         | 29/378 [00:12<02:24,  2.41it/s]\r  8%|▊         | 30/378 [00:12<02:24,  2.41it/s]\r  8%|▊         | 31/378 [00:13<02:24,  2.41it/s]\r  8%|▊         | 32/378 [00:13<02:23,  2.41it/s]\r  9%|▊         | 33/378 [00:13<02:23,  2.40it/s]\r  9%|▉         | 34/378 [00:14<02:22,  2.41it/s]\r  9%|▉         | 35/378 [00:14<02:22,  2.41it/s]\r 10%|▉         | 36/378 [00:15<02:22,  2.41it/s]\r 10%|▉         | 37/378 [00:15<02:21,  2.40it/s]\r 10%|█         | 38/378 [00:15<02:21,  2.40it/s]\r 10%|█         | 39/378 [00:16<02:20,  2.41it/s]\r 11%|█         | 40/378 [00:16<02:20,  2.40it/s]\r 11%|█         | 41/378 [00:17<02:20,  2.40it/s]\r 11%|█         | 42/378 [00:17<02:19,  2.41it/s]\r 11%|█▏        | 43/378 [00:18<02:19,  2.40it/s]\r 12%|█▏        | 44/378 [00:18<02:18,  2.41it/s]\r 12%|█▏        | 45/378 [00:18<02:18,  2.40it/s]\r 12%|█▏        | 46/378 [00:19<02:17,  2.41it/s]\r 12%|█▏        | 47/378 [00:19<02:17,  2.40it/s]\r 13%|█▎        | 48/378 [00:20<02:17,  2.41it/s]\r 13%|█▎        | 49/378 [00:20<02:16,  2.40it/s]\r 13%|█▎        | 50/378 [00:20<02:16,  2.39it/s]\r 13%|█▎        | 51/378 [00:21<02:16,  2.39it/s]\r 14%|█▍        | 52/378 [00:21<02:16,  2.39it/s]\r 14%|█▍        | 53/378 [00:22<02:16,  2.38it/s]\r 14%|█▍        | 54/378 [00:22<02:15,  2.39it/s]\r 15%|█▍        | 55/378 [00:23<02:15,  2.39it/s]\r 15%|█▍        | 56/378 [00:23<02:15,  2.38it/s]\r 15%|█▌        | 57/378 [00:23<02:14,  2.39it/s]\r 15%|█▌        | 58/378 [00:24<02:13,  2.39it/s]\r 16%|█▌        | 59/378 [00:24<02:13,  2.38it/s]\r 16%|█▌        | 60/378 [00:25<02:13,  2.38it/s]\r 16%|█▌        | 61/378 [00:25<02:12,  2.39it/s]\r 16%|█▋        | 62/378 [00:26<02:12,  2.39it/s]\r 17%|█▋        | 63/378 [00:26<02:12,  2.38it/s]\r 17%|█▋        | 64/378 [00:26<02:11,  2.39it/s]\r 17%|█▋        | 65/378 [00:27<02:11,  2.39it/s]\r 17%|█▋        | 66/378 [00:27<02:10,  2.38it/s]\r 18%|█▊        | 67/378 [00:28<02:10,  2.39it/s]\r 18%|█▊        | 68/378 [00:28<02:10,  2.38it/s]\r 18%|█▊        | 69/378 [00:28<02:10,  2.38it/s]\r 19%|█▊        | 70/378 [00:29<02:09,  2.37it/s]\r 19%|█▉        | 71/378 [00:29<02:09,  2.37it/s]\r 19%|█▉        | 72/378 [00:30<02:09,  2.37it/s]\r 19%|█▉        | 73/378 [00:30<02:08,  2.37it/s]\r 20%|█▉        | 74/378 [00:31<02:07,  2.38it/s]\r 20%|█▉        | 75/378 [00:31<02:07,  2.37it/s]\r 20%|██        | 76/378 [00:31<02:07,  2.37it/s]\r 20%|██        | 77/378 [00:32<02:07,  2.37it/s]\r 21%|██        | 78/378 [00:32<02:06,  2.37it/s]\r 21%|██        | 79/378 [00:33<02:05,  2.37it/s]\r 21%|██        | 80/378 [00:33<02:05,  2.37it/s]\r 21%|██▏       | 81/378 [00:34<02:05,  2.37it/s]\r 22%|██▏       | 82/378 [00:34<02:05,  2.36it/s]\r 22%|██▏       | 83/378 [00:34<02:05,  2.36it/s]\r 22%|██▏       | 84/378 [00:35<02:04,  2.36it/s]\r 22%|██▏       | 85/378 [00:35<02:04,  2.35it/s]\r 23%|██▎       | 86/378 [00:36<02:03,  2.36it/s]\r 23%|██▎       | 87/378 [00:36<02:03,  2.36it/s]\r 23%|██▎       | 88/378 [00:37<02:03,  2.35it/s]\r 24%|██▎       | 89/378 [00:37<02:02,  2.35it/s]\r 24%|██▍       | 90/378 [00:37<02:02,  2.35it/s]\r 24%|██▍       | 91/378 [00:38<02:02,  2.34it/s]\r 24%|██▍       | 92/378 [00:38<02:01,  2.35it/s]\r 25%|██▍       | 93/378 [00:39<02:01,  2.35it/s]\r 25%|██▍       | 94/378 [00:39<02:01,  2.34it/s]\r 25%|██▌       | 95/378 [00:39<02:00,  2.35it/s]\r 25%|██▌       | 96/378 [00:40<02:00,  2.35it/s]\r 26%|██▌       | 97/378 [00:40<01:59,  2.35it/s]\r 26%|██▌       | 98/378 [00:41<01:59,  2.35it/s]\r 26%|██▌       | 99/378 [00:41<01:58,  2.35it/s]\r 26%|██▋       | 100/378 [00:42<01:58,  2.35it/s]\r 27%|██▋       | 101/378 [00:42<01:58,  2.34it/s]\r 27%|██▋       | 102/378 [00:42<01:57,  2.35it/s]\r 27%|██▋       | 103/378 [00:43<01:57,  2.35it/s]\r 28%|██▊       | 104/378 [00:43<01:56,  2.35it/s]\r 28%|██▊       | 105/378 [00:44<01:56,  2.35it/s]\r 28%|██▊       | 106/378 [00:44<01:56,  2.34it/s]\r 28%|██▊       | 107/378 [00:45<01:55,  2.34it/s]\r 29%|██▊       | 108/378 [00:45<01:55,  2.34it/s]\r 29%|██▉       | 109/378 [00:45<01:54,  2.34it/s]\r 29%|██▉       | 110/378 [00:46<01:54,  2.35it/s]\r 29%|██▉       | 111/378 [00:46<01:53,  2.34it/s]\r 30%|██▉       | 112/378 [00:47<01:53,  2.34it/s]\r 30%|██▉       | 113/378 [00:47<01:53,  2.33it/s]\r 30%|███       | 114/378 [00:48<01:53,  2.33it/s]\r 30%|███       | 115/378 [00:48<01:52,  2.33it/s]\r 31%|███       | 116/378 [00:48<01:52,  2.33it/s]\r 31%|███       | 117/378 [00:49<01:51,  2.33it/s]\r 31%|███       | 118/378 [00:49<01:51,  2.34it/s]\r 31%|███▏      | 119/378 [00:50<01:50,  2.34it/s]\r 32%|███▏      | 120/378 [00:50<01:50,  2.34it/s]\r 32%|███▏      | 121/378 [00:51<01:49,  2.34it/s]\r 32%|███▏      | 122/378 [00:51<01:49,  2.34it/s]\r 33%|███▎      | 123/378 [00:51<01:49,  2.33it/s]\r 33%|███▎      | 124/378 [00:52<01:48,  2.33it/s]\r 33%|███▎      | 125/378 [00:52<01:48,  2.33it/s]\r 33%|███▎      | 126/378 [00:53<01:47,  2.34it/s]\r 34%|███▎      | 127/378 [00:53<01:47,  2.34it/s]\r 34%|███▍      | 128/378 [00:54<01:47,  2.33it/s]\r 34%|███▍      | 129/378 [00:54<01:46,  2.33it/s]\r 34%|███▍      | 130/378 [00:54<01:46,  2.32it/s]\r 35%|███▍      | 131/378 [00:55<01:46,  2.33it/s]\r 35%|███▍      | 132/378 [00:55<01:45,  2.33it/s]\r 35%|███▌      | 133/378 [00:56<01:45,  2.33it/s]\r 35%|███▌      | 134/378 [00:56<01:45,  2.32it/s]\r 36%|███▌      | 135/378 [00:57<01:44,  2.32it/s]\r 36%|███▌      | 136/378 [00:57<01:43,  2.33it/s]\r 36%|███▌      | 137/378 [00:57<01:43,  2.32it/s]\r 37%|███▋      | 138/378 [00:58<01:43,  2.32it/s]\r 37%|███▋      | 139/378 [00:58<01:43,  2.32it/s]\r 37%|███▋      | 140/378 [00:59<01:43,  2.31it/s]\r 37%|███▋      | 141/378 [00:59<01:42,  2.31it/s]\r 38%|███▊      | 142/378 [01:00<01:42,  2.31it/s]\r 38%|███▊      | 143/378 [01:00<01:41,  2.31it/s]\r 38%|███▊      | 144/378 [01:00<01:41,  2.31it/s]\r 38%|███▊      | 145/378 [01:01<01:41,  2.30it/s]\r 39%|███▊      | 146/378 [01:01<01:40,  2.31it/s]\r 39%|███▉      | 147/378 [01:02<01:40,  2.30it/s]\r 39%|███▉      | 148/378 [01:02<01:39,  2.30it/s]\r 39%|███▉      | 149/378 [01:03<01:39,  2.31it/s]\r 40%|███▉      | 150/378 [01:03<01:39,  2.30it/s]\r 40%|███▉      | 151/378 [01:04<01:38,  2.31it/s]\r 40%|████      | 152/378 [01:04<01:38,  2.30it/s]\r 40%|████      | 153/378 [01:04<01:38,  2.29it/s]\r 41%|████      | 154/378 [01:05<01:37,  2.29it/s]\r 41%|████      | 155/378 [01:05<01:37,  2.28it/s]\r 41%|████▏     | 156/378 [01:06<01:37,  2.29it/s]\r 42%|████▏     | 157/378 [01:06<01:36,  2.29it/s]\r 42%|████▏     | 158/378 [01:07<01:36,  2.28it/s]\r 42%|████▏     | 159/378 [01:07<01:35,  2.28it/s]\r 42%|████▏     | 160/378 [01:07<01:35,  2.29it/s]\r 43%|████▎     | 161/378 [01:08<01:34,  2.29it/s]\r 43%|████▎     | 162/378 [01:08<01:34,  2.29it/s]\r 43%|████▎     | 163/378 [01:09<01:34,  2.28it/s]\r 43%|████▎     | 164/378 [01:09<01:33,  2.29it/s]\r 44%|████▎     | 165/378 [01:10<01:33,  2.28it/s]\r 44%|████▍     | 166/378 [01:10<01:32,  2.29it/s]\r 44%|████▍     | 167/378 [01:11<01:32,  2.29it/s]\r 44%|████▍     | 168/378 [01:11<01:31,  2.28it/s]\r 45%|████▍     | 169/378 [01:11<01:31,  2.28it/s]\r 45%|████▍     | 170/378 [01:12<01:31,  2.28it/s]\r 45%|████▌     | 171/378 [01:12<01:30,  2.28it/s]\r 46%|████▌     | 172/378 [01:13<01:30,  2.29it/s]\r 46%|████▌     | 173/378 [01:13<01:29,  2.28it/s]\r 46%|████▌     | 174/378 [01:14<01:29,  2.28it/s]\r 46%|████▋     | 175/378 [01:14<01:28,  2.28it/s]\r 47%|████▋     | 176/378 [01:14<01:28,  2.27it/s]\r 47%|████▋     | 177/378 [01:15<01:28,  2.27it/s]\r 47%|████▋     | 178/378 [01:15<01:28,  2.27it/s]\r 47%|████▋     | 179/378 [01:16<01:27,  2.27it/s]\r 48%|████▊     | 180/378 [01:16<01:27,  2.27it/s]\r 48%|████▊     | 181/378 [01:17<01:26,  2.27it/s]\r 48%|████▊     | 182/378 [01:17<01:26,  2.27it/s]\r 48%|████▊     | 183/378 [01:18<01:26,  2.27it/s]\r 49%|████▊     | 184/378 [01:18<01:25,  2.27it/s]\r 49%|████▉     | 185/378 [01:18<01:25,  2.26it/s]\r 49%|████▉     | 186/378 [01:19<01:24,  2.26it/s]\r 49%|████▉     | 187/378 [01:19<01:24,  2.26it/s]\r 50%|████▉     | 188/378 [01:20<01:24,  2.26it/s]\r 50%|█████     | 189/378 [01:20<01:23,  2.25it/s]\r 50%|█████     | 190/378 [01:21<01:23,  2.25it/s]\r 51%|█████     | 191/378 [01:21<01:22,  2.25it/s]\r 51%|█████     | 192/378 [01:22<01:22,  2.25it/s]\r 51%|█████     | 193/378 [01:22<01:22,  2.25it/s]\r 51%|█████▏    | 194/378 [01:22<01:21,  2.25it/s]\r 52%|█████▏    | 195/378 [01:23<01:21,  2.25it/s]\r 52%|█████▏    | 196/378 [01:23<01:20,  2.25it/s]\r 52%|█████▏    | 197/378 [01:24<01:20,  2.25it/s]\r 52%|█████▏    | 198/378 [01:24<01:20,  2.25it/s]\r 53%|█████▎    | 199/378 [01:25<01:19,  2.25it/s]\r 53%|█████▎    | 200/378 [01:25<01:19,  2.24it/s]\r 53%|█████▎    | 201/378 [01:26<01:18,  2.25it/s]\r 53%|█████▎    | 202/378 [01:26<01:18,  2.25it/s]\r 54%|█████▎    | 203/378 [01:26<01:17,  2.25it/s]\r 54%|█████▍    | 204/378 [01:27<01:17,  2.24it/s]\r 54%|█████▍    | 205/378 [01:27<01:17,  2.24it/s]\r 54%|█████▍    | 206/378 [01:28<01:16,  2.25it/s]\r 55%|█████▍    | 207/378 [01:28<01:16,  2.25it/s]\r 55%|█████▌    | 208/378 [01:29<01:15,  2.24it/s]\r 55%|█████▌    | 209/378 [01:29<01:15,  2.24it/s]\r 56%|█████▌    | 210/378 [01:30<01:15,  2.24it/s]\r 56%|█████▌    | 211/378 [01:30<01:14,  2.23it/s]\r 56%|█████▌    | 212/378 [01:30<01:14,  2.23it/s]\r 56%|█████▋    | 213/378 [01:31<01:13,  2.23it/s]\r 57%|█████▋    | 214/378 [01:31<01:13,  2.23it/s]\r 57%|█████▋    | 215/378 [01:32<01:13,  2.23it/s]\r 57%|█████▋    | 216/378 [01:32<01:12,  2.23it/s]\r 57%|█████▋    | 217/378 [01:33<01:12,  2.22it/s]\r 58%|█████▊    | 218/378 [01:33<01:12,  2.22it/s]\r 58%|█████▊    | 219/378 [01:34<01:11,  2.22it/s]\r 58%|█████▊    | 220/378 [01:34<01:11,  2.22it/s]\r 58%|█████▊    | 221/378 [01:35<01:10,  2.22it/s]\r 59%|█████▊    | 222/378 [01:35<01:10,  2.22it/s]\r 59%|█████▉    | 223/378 [01:35<01:10,  2.21it/s]\r 59%|█████▉    | 224/378 [01:36<01:09,  2.21it/s]\r 60%|█████▉    | 225/378 [01:36<01:09,  2.21it/s]\r 60%|█████▉    | 226/378 [01:37<01:08,  2.21it/s]\r 60%|██████    | 227/378 [01:37<01:08,  2.21it/s]\r 60%|██████    | 228/378 [01:38<01:07,  2.21it/s]\r 61%|██████    | 229/378 [01:38<01:07,  2.20it/s]\r 61%|██████    | 230/378 [01:39<01:07,  2.20it/s]\r 61%|██████    | 231/378 [01:39<01:06,  2.20it/s]\r 61%|██████▏   | 232/378 [01:40<01:06,  2.20it/s]\r 62%|██████▏   | 233/378 [01:40<01:05,  2.20it/s]\r 62%|██████▏   | 234/378 [01:40<01:05,  2.20it/s]\r 62%|██████▏   | 235/378 [01:41<01:05,  2.20it/s]\r 62%|██████▏   | 236/378 [01:41<01:04,  2.20it/s]\r 63%|██████▎   | 237/378 [01:42<01:04,  2.19it/s]\r 63%|██████▎   | 238/378 [01:42<01:04,  2.18it/s]\r 63%|██████▎   | 239/378 [01:43<01:03,  2.18it/s]\r 63%|██████▎   | 240/378 [01:43<01:03,  2.18it/s]\r 64%|██████▍   | 241/378 [01:44<01:02,  2.19it/s]\r 64%|██████▍   | 242/378 [01:44<01:02,  2.18it/s]\r 64%|██████▍   | 243/378 [01:45<01:02,  2.18it/s]\r 65%|██████▍   | 244/378 [01:45<01:01,  2.17it/s]\r 65%|██████▍   | 245/378 [01:46<01:01,  2.17it/s]\r 65%|██████▌   | 246/378 [01:46<01:00,  2.17it/s]\r 65%|██████▌   | 247/378 [01:46<01:00,  2.17it/s]\r 66%|██████▌   | 248/378 [01:47<00:59,  2.17it/s]\r 66%|██████▌   | 249/378 [01:47<00:59,  2.17it/s]\r 66%|██████▌   | 250/378 [01:48<00:59,  2.17it/s]\r 66%|██████▋   | 251/378 [01:48<00:58,  2.17it/s]\r 67%|██████▋   | 252/378 [01:49<00:58,  2.17it/s]\r 67%|██████▋   | 253/378 [01:49<00:57,  2.17it/s]\r 67%|██████▋   | 254/378 [01:50<00:57,  2.16it/s]\r 67%|██████▋   | 255/378 [01:50<00:56,  2.16it/s]\r 68%|██████▊   | 256/378 [01:51<00:56,  2.17it/s]\r 68%|██████▊   | 257/378 [01:51<00:55,  2.16it/s]\r 68%|██████▊   | 258/378 [01:52<00:55,  2.16it/s]\r 69%|██████▊   | 259/378 [01:52<00:55,  2.15it/s]\r 69%|██████▉   | 260/378 [01:52<00:54,  2.15it/s]\r 69%|██████▉   | 261/378 [01:53<00:54,  2.15it/s]\r 69%|██████▉   | 262/378 [01:53<00:53,  2.15it/s]\r 70%|██████▉   | 263/378 [01:54<00:53,  2.15it/s]\r 70%|██████▉   | 264/378 [01:54<00:52,  2.15it/s]\r 70%|███████   | 265/378 [01:55<00:52,  2.16it/s]\r 70%|███████   | 266/378 [01:55<00:51,  2.16it/s]\r 71%|███████   | 267/378 [01:56<00:51,  2.16it/s]\r 71%|███████   | 268/378 [01:56<00:51,  2.15it/s]\r 71%|███████   | 269/378 [01:57<00:50,  2.15it/s]\r 71%|███████▏  | 270/378 [01:57<00:50,  2.16it/s]\r 72%|███████▏  | 271/378 [01:58<00:49,  2.15it/s]\r 72%|███████▏  | 272/378 [01:58<00:49,  2.14it/s]\r 72%|███████▏  | 273/378 [01:58<00:48,  2.14it/s]\r 72%|███████▏  | 274/378 [01:59<00:48,  2.15it/s]\r 73%|███████▎  | 275/378 [01:59<00:47,  2.15it/s]\r 73%|███████▎  | 276/378 [02:00<00:47,  2.15it/s]\r 73%|███████▎  | 277/378 [02:00<00:46,  2.16it/s]\r 74%|███████▎  | 278/378 [02:01<00:46,  2.16it/s]\r 74%|███████▍  | 279/378 [02:01<00:45,  2.17it/s]\r 74%|███████▍  | 280/378 [02:02<00:45,  2.16it/s]\r 74%|███████▍  | 281/378 [02:02<00:44,  2.16it/s]\r 75%|███████▍  | 282/378 [02:03<00:44,  2.17it/s]\r 75%|███████▍  | 283/378 [02:03<00:43,  2.17it/s]\r 75%|███████▌  | 284/378 [02:04<00:43,  2.17it/s]\r 75%|███████▌  | 285/378 [02:04<00:42,  2.17it/s]\r 76%|███████▌  | 286/378 [02:04<00:42,  2.18it/s]\r 76%|███████▌  | 287/378 [02:05<00:41,  2.18it/s]\r 76%|███████▌  | 288/378 [02:05<00:41,  2.18it/s]\r 76%|███████▋  | 289/378 [02:06<00:40,  2.18it/s]\r 77%|███████▋  | 290/378 [02:06<00:40,  2.19it/s]\r 77%|███████▋  | 291/378 [02:07<00:39,  2.18it/s]\r 77%|███████▋  | 292/378 [02:07<00:39,  2.18it/s]\r 78%|███████▊  | 293/378 [02:08<00:38,  2.19it/s]\r 78%|███████▊  | 294/378 [02:08<00:38,  2.17it/s]\r 78%|███████▊  | 295/378 [02:09<00:38,  2.18it/s]\r 78%|███████▊  | 296/378 [02:09<00:37,  2.18it/s]\r 79%|███████▊  | 297/378 [02:10<00:36,  2.19it/s]\r 79%|███████▉  | 298/378 [02:10<00:36,  2.19it/s]\r 79%|███████▉  | 299/378 [02:10<00:35,  2.20it/s]\r 79%|███████▉  | 300/378 [02:11<00:35,  2.21it/s]\r 80%|███████▉  | 301/378 [02:11<00:34,  2.20it/s]\r 80%|███████▉  | 302/378 [02:12<00:34,  2.21it/s]\r 80%|████████  | 303/378 [02:12<00:33,  2.21it/s]\r 80%|████████  | 304/378 [02:13<00:33,  2.21it/s]\r 81%|████████  | 305/378 [02:13<00:33,  2.21it/s]\r 81%|████████  | 306/378 [02:14<00:32,  2.21it/s]\r 81%|████████  | 307/378 [02:14<00:32,  2.21it/s]\r 81%|████████▏ | 308/378 [02:14<00:31,  2.21it/s]\r 82%|████████▏ | 309/378 [02:15<00:31,  2.21it/s]\r 82%|████████▏ | 310/378 [02:15<00:30,  2.21it/s]\r 82%|████████▏ | 311/378 [02:16<00:30,  2.21it/s]\r 83%|████████▎ | 312/378 [02:16<00:29,  2.21it/s]\r 83%|████████▎ | 313/378 [02:17<00:29,  2.21it/s]\r 83%|████████▎ | 314/378 [02:17<00:28,  2.21it/s]\r 83%|████████▎ | 315/378 [02:18<00:28,  2.22it/s]\r 84%|████████▎ | 316/378 [02:18<00:27,  2.22it/s]\r 84%|████████▍ | 317/378 [02:19<00:27,  2.22it/s]\r 84%|████████▍ | 318/378 [02:19<00:27,  2.22it/s]\r 84%|████████▍ | 319/378 [02:19<00:26,  2.22it/s]\r 85%|████████▍ | 320/378 [02:20<00:26,  2.23it/s]\r 85%|████████▍ | 321/378 [02:20<00:25,  2.23it/s]\r 85%|████████▌ | 322/378 [02:21<00:25,  2.22it/s]\r 85%|████████▌ | 323/378 [02:21<00:24,  2.22it/s]\r 86%|████████▌ | 324/378 [02:22<00:24,  2.22it/s]\r 86%|████████▌ | 325/378 [02:22<00:23,  2.23it/s]\r 86%|████████▌ | 326/378 [02:23<00:23,  2.23it/s]\r 87%|████████▋ | 327/378 [02:23<00:22,  2.22it/s]\r 87%|████████▋ | 328/378 [02:23<00:22,  2.22it/s]\r 87%|████████▋ | 329/378 [02:24<00:22,  2.22it/s]\r 87%|████████▋ | 330/378 [02:24<00:21,  2.22it/s]\r 88%|████████▊ | 331/378 [02:25<00:21,  2.23it/s]\r 88%|████████▊ | 332/378 [02:25<00:20,  2.23it/s]\r 88%|████████▊ | 333/378 [02:26<00:20,  2.22it/s]\r 88%|████████▊ | 334/378 [02:26<00:19,  2.22it/s]\r 89%|████████▊ | 335/378 [02:27<00:19,  2.22it/s]\r 89%|████████▉ | 336/378 [02:27<00:18,  2.23it/s]\r 89%|████████▉ | 337/378 [02:28<00:18,  2.23it/s]\r 89%|████████▉ | 338/378 [02:28<00:17,  2.24it/s]\r 90%|████████▉ | 339/378 [02:28<00:17,  2.24it/s]\r 90%|████████▉ | 340/378 [02:29<00:16,  2.24it/s]\r 90%|█████████ | 341/378 [02:29<00:16,  2.24it/s]\r 90%|█████████ | 342/378 [02:30<00:16,  2.23it/s]\r 91%|█████████ | 343/378 [02:30<00:15,  2.23it/s]\r 91%|█████████ | 344/378 [02:31<00:15,  2.23it/s]\r 91%|█████████▏| 345/378 [02:31<00:14,  2.23it/s]\r 92%|█████████▏| 346/378 [02:32<00:14,  2.23it/s]\r 92%|█████████▏| 347/378 [02:32<00:13,  2.23it/s]\r 92%|█████████▏| 348/378 [02:32<00:13,  2.24it/s]\r 92%|█████████▏| 349/378 [02:33<00:12,  2.24it/s]\r 93%|█████████▎| 350/378 [02:33<00:12,  2.24it/s]\r 93%|█████████▎| 351/378 [02:34<00:12,  2.23it/s]\r 93%|█████████▎| 352/378 [02:34<00:11,  2.23it/s]\r 93%|█████████▎| 353/378 [02:35<00:11,  2.23it/s]\r 94%|█████████▎| 354/378 [02:35<00:10,  2.23it/s]\r 94%|█████████▍| 355/378 [02:36<00:10,  2.23it/s]\r 94%|█████████▍| 356/378 [02:36<00:09,  2.23it/s]\r 94%|█████████▍| 357/378 [02:36<00:09,  2.23it/s]\r 95%|█████████▍| 358/378 [02:37<00:08,  2.23it/s]\r 95%|█████████▍| 359/378 [02:37<00:08,  2.23it/s]\r 95%|█████████▌| 360/378 [02:38<00:08,  2.22it/s]\r 96%|█████████▌| 361/378 [02:38<00:07,  2.22it/s]\r 96%|█████████▌| 362/378 [02:39<00:07,  2.23it/s]\r 96%|█████████▌| 363/378 [02:39<00:06,  2.23it/s]\r 96%|█████████▋| 364/378 [02:40<00:06,  2.23it/s]\r 97%|█████████▋| 365/378 [02:40<00:05,  2.23it/s]\r 97%|█████████▋| 366/378 [02:41<00:05,  2.22it/s]\r 97%|█████████▋| 367/378 [02:41<00:04,  2.22it/s]\r 97%|█████████▋| 368/378 [02:41<00:04,  2.22it/s]\r 98%|█████████▊| 369/378 [02:42<00:04,  2.23it/s]\r 98%|█████████▊| 370/378 [02:42<00:03,  2.23it/s]\r 98%|█████████▊| 371/378 [02:43<00:03,  2.23it/s]\r 98%|█████████▊| 372/378 [02:43<00:02,  2.23it/s]\r 99%|█████████▊| 373/378 [02:44<00:02,  2.22it/s]\r 99%|█████████▉| 374/378 [02:44<00:01,  2.22it/s]\r 99%|█████████▉| 375/378 [02:45<00:01,  2.22it/s]\r 99%|█████████▉| 376/378 [02:45<00:00,  2.22it/s]\r100%|█████████▉| 377/378 [02:45<00:00,  2.21it/s]\r100%|██████████| 378/378 [02:46<00:00,  2.22it/s]\r100%|██████████| 378/378 [02:46<00:00,  2.27it/s]\n","/usr/local/lib/python3.6/dist-packages/transformers/trainer.py:1118: FutureWarning: This method is deprecated, use `Trainer.is_world_process_zero()` instead.\n","  warnings.warn(\"This method is deprecated, use `Trainer.is_world_process_zero()` instead.\", FutureWarning)\n","10/24/2020 20:18:46 - INFO - __main__ -   *** Evaluate ***\n","\r  0%|          | 0/20 [00:00<?, ?it/s]\r 10%|█         | 2/20 [00:01<00:09,  1.81it/s]\r 15%|█▌        | 3/20 [00:02<00:12,  1.39it/s]\r 20%|██        | 4/20 [00:03<00:13,  1.19it/s]\r 25%|██▌       | 5/20 [00:04<00:13,  1.08it/s]\r 30%|███       | 6/20 [00:05<00:13,  1.01it/s]\r 35%|███▌      | 7/20 [00:06<00:13,  1.03s/it]\r 40%|████      | 8/20 [00:07<00:12,  1.06s/it]\r 45%|████▌     | 9/20 [00:08<00:11,  1.08s/it]\r 50%|█████     | 10/20 [00:10<00:10,  1.10s/it]\r 55%|█████▌    | 11/20 [00:11<00:09,  1.11s/it]\r 60%|██████    | 12/20 [00:12<00:08,  1.12s/it]\r 65%|██████▌   | 13/20 [00:13<00:07,  1.12s/it]\r 70%|███████   | 14/20 [00:14<00:06,  1.13s/it]\r 75%|███████▌  | 15/20 [00:15<00:05,  1.13s/it]\r 80%|████████  | 16/20 [00:16<00:04,  1.13s/it]\r 85%|████████▌ | 17/20 [00:18<00:03,  1.14s/it]\r 90%|█████████ | 18/20 [00:19<00:02,  1.14s/it]\r 95%|█████████▌| 19/20 [00:20<00:01,  1.14s/it]\r100%|██████████| 20/20 [00:21<00:00,  1.08s/it]10/24/2020 20:19:08 - INFO - __main__ -   ***** Eval results *****\n","10/24/2020 20:19:08 - INFO - __main__ -     perplexity = 1.7268832142682369\n","\r100%|██████████| 20/20 [00:21<00:00,  1.08s/it]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"s0Fwb6TEUgj1"},"source":["## Results\n","\n","To use it, you can run something like"]},{"cell_type":"code","metadata":{"id":"EGAlyaB3Sfiu","executionInfo":{"status":"ok","timestamp":1603571204030,"user_tz":300,"elapsed":9514,"user":{"displayName":"Neil Kaushikkar","photoUrl":"","userId":"04245653301361239178"}},"outputId":"a414789f-c254-4284-b3d8-162a599bf2b1","colab":{"base_uri":"https://localhost:8080/","height":649}},"source":["from transformers import AutoTokenizer, AutoModelWithLMHead, pipeline\n","import torch\n","import numpy as np\n","\n","OUTPUT_DIR = \"./output_mine\"\n","device = 'cpu'\n","\n","# tokenizer = AutoTokenizer.from_pretrained(OUTPUT_DIR)\n","# model = AutoModelWithLMHead.from_pretrained(OUTPUT_DIR)\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"yuvraj/summarizer-cnndm\") \n","model = AutoModelWithLMHead.from_pretrained(\"yuvraj/summarizer-cnndm\")\n","\n","# model = model.to(device)\n","model = model.to(device)\n","\n","# summarizer = pipeline('summarization', model=model, tokenizer=tokenizer)\n","summarizer = pipeline('summarization', model=model, tokenizer=tokenizer)\n","                                        \n","# def generate(input_str, model=model, tokenizer=tokenizer, length=250, n=5):\n","#   output_text = input_str\n","#   summarizer = pipeline('summarization', model=model, tokenizer=tokenizer)\n","#   for word_num in range(length):\n","#     data = unmasker(output_text)\n","#     probs = []\n","#     current_prob = 0\n","#     for word in data:\n","#       current_prob += word['score']\n","#       probs.append((current_prob, word['token_str']))\n","#     choice = np.random.uniform(high=current_prob)\n","#     probs.append(choice, \"\")\n","#     probs = sorted(probs)\n","#     index = probs.index((choice, \"\"))\n","#     output_text = output_text + probs[index-1][1] + \" \"\n","#   return output_text\n","\n","# generated_text = generate(\" = University of Illinois = \\n\")\n","# print(generated_text)\n","\n","text = newsroom[0]['text'].split(' ')\n","text = ' '.join(text[:691])\n","\n","print(text + \"\\n\")\n","print(summarizer(text))\n","\n","print(\"\\n\\n\")\n","\n","# summarizer(text)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/modeling_auto.py:825: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["HAMBURG, Germany, June 3  As he left the soccer field after a club match in the eastern German city of Halle on March 25, the Nigerian forward Adebowale Ogungbure was spit upon, jeered with racial remarks and mocked with monkey noises. In rebuke, he placed two fingers under his nose to simulate a Hitler mustache and thrust his arm in a Nazi salute.\n","\n","Marc Zoro, right, an Ivory Coast native, was a target of racial slurs from the home fans in Messina, Italy. Adriano, a star with Inter Milan, tried to persuade him to stay on the field.\n","\n","From now until its conclusion on July 9, Jeff Z. Klein and other staff members of The Times and International Herald Tribune will track the world's most popular sporting event.\n","\n","Your guide to the games in Germany: teams, rosters, schedules, statistics, venues and more.\n","\n","In April, the American defender Oguchi Onyewu, playing for his professional club team in Belgium, dismissively gestured toward fans who were making simian chants at him. Then, as he went to throw the ball inbounds, Onyewu said a fan of the opposing team reached over a barrier and punched him in the face.\n","\n","International soccer has been plagued for years by violence among fans, including racial incidents. But FIFA, soccer's Zurich-based world governing body, said there has been a recent surge in discriminatory behavior toward blacks by fans and other players, an escalation that has dovetailed with the signing of more players from Africa and Latin America by elite European clubs.\n","\n","This \"deplorable trend,\" as FIFA has called it, now threatens to embarrass the sport on its grandest stage, the World Cup, which opens June 9 for a monthlong run in 12 cities around Germany. More than 30 billion cumulative television viewers are expected to watch part of the competition and Joseph S. Blatter, FIFA's president, has vowed to crack down on racist behavior during the tournament.\n","\n","Underlining FIFA's concerns, the issue has been included on the agenda at its biannual Congress, scheduled to be held this week in Munich. A campaign against bigotry includes \"Say No to Racism\" stadium banners, television commercials, and team captains making pregame speeches during the quarterfinals of the 32-team tournament.\n","\n","Players, coaches and officials have been threatened with sanctions. But FIFA has said it would not be practical to use the harshest penalties available to punish misbehaving fans  halting matches, holding games in empty stadiums and deducting points that teams receive for victories and ties.\n","\n","Players and antiracism experts said they expected offensive behavior during the tournament, including monkey-like chanting; derisive singing; the hanging of banners that reflect neofascist and racist beliefs; and perhaps the tossing of bananas or banana peels, all familiar occurrences during matches in Spain, Italy, eastern Germany and eastern Europe.\n","\n","\"For us it's quite clear this is a reflection of underlying tensions that exist in European societies,\" said Piara Powar, director of the London-based antiracist soccer organization Kick It Out. He said of Eastern Europe: \"Poverty, unemployment, is a problem. Indigenous people are looking for easy answers to blame. Often newcomers bear the brunt of the blame.\"\n","\n","Yet experts and players also said they believed the racist behavior would be more constrained at the World Cup than it was during play in various domestic leagues around Europe, because of increased security, the international makeup of the crowds, higher ticket prices and a sense that spectators would be generally well behaved on soccer's grandest stage.\n","\n","\"We have to differentiate inside and outside the stadium,\" said Kurt Wachter, project coordinator for the Vienna-based Football Against Racism in Europe, a network of organizations that seeks to fight bigotry and xenophobia in 35 countries.\n","\n","\"Racism is a feature of many football leagues inside and outside Europe,\" said Wachter, who expects most problems to occur outside stadiums where crowds are less controlled. \"We're sure we will see some things we're used to seeing. It won't stop because of the World Cup.\"\n","\n","Particularly worrisome are the possibilities of attacks by extremist groups on spectators and visitors in train stations, bars, restaurants and open areas near the stadiums, Wachter and other experts said. To promote tolerance, he said his organization would organize street soccer matches outside World Cup\n","\n","[{'summary_text': 'FIFA says it will not use the harshest penalties available to punish misbehaving fans .'}]\n","\n","\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KvLfcwTOUnlt"},"source":["## Compressing/Zipping Model\n","\n","\n","In order for us to preserve this model, we should compress it and save it somewhere. This can be done easily with"]},{"cell_type":"code","metadata":{"id":"W4zDMZZdUkW2"},"source":["! tar -czf gpt2-tuned.tar.gz output/"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LT8ffxEsVL0-"},"source":["which creates a file called `gpt2-tuned.tar.gz`"]},{"cell_type":"markdown","metadata":{"id":"8vGGDE3bVO6s"},"source":["## Saving it to Google Drive"]},{"cell_type":"code","metadata":{"id":"X9J6NUCkVPpn","executionInfo":{"status":"ok","timestamp":1591995754331,"user_tz":240,"elapsed":1229,"user":{"displayName":"Joey Sham","photoUrl":"","userId":"07509763358611462220"}},"outputId":"92ecdae4-67e4-4d90-e91d-2cea4e5f1411","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_MmLCVxSXDc-"},"source":["Now you can copy your output model to your Google Drive by running"]},{"cell_type":"code","metadata":{"id":"XyUwAAqJXMxS"},"source":["!cp gpt2-tuned.tar.gz /content/drive/My\\ Drive/"],"execution_count":null,"outputs":[]}]}