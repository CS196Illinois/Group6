{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FineTuneWithCustomDataset.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOxKSXiAPdFNDF6uHWIVNHl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"XBAoSr1aRq_1"},"source":["# **Import Statements:**"]},{"cell_type":"code","metadata":{"id":"otG2bxKYSAKh"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd \"/content/drive/My Drive/CS196Project/Group6/finetuning\"\n","\n","!pip install -r requirements.txt\n","\n","import torch\n","from datasets import load_dataset"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lP_AC2FB0KTy"},"source":["Get all required code for finetuning."]},{"cell_type":"code","metadata":{"id":"nFf8kZGUmqdp"},"source":["%%bash\n","cd \"/content/drive/My Drive/CS196Project/Group6/finetuning/seq2seq\"\n","\n","# These files are already stored in our GitHub Repo\n","\n","# wget https://raw.githubusercontent.com/huggingface/transformers/master/examples/seq2seq/finetune.py\n","# wget https://raw.githubusercontent.com/huggingface/transformers/master/examples/seq2seq/callbacks.py\n","# wget https://raw.githubusercontent.com/huggingface/transformers/master/examples/seq2seq/utils.py\n","# wget https://raw.githubusercontent.com/huggingface/transformers/master/examples/seq2seq/sentence_splitter.py\n","# wget https://raw.githubusercontent.com/huggingface/transformers/master/examples/lightning_base.py\n","# wget https://raw.githubusercontent.com/huggingface/transformers/master/examples/requirements.txt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SNpBvEroSeie"},"source":["# **Load Datasets:**\n","\n"," TODO: format newsroom\n"]},{"cell_type":"code","metadata":{"id":"Qh-jjeIcSik0"},"source":["# newsroom = load_dataset('newsroom', data_dir='/content/drive/My Drive/CS196Project/newsroom')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y_4iOBT8gOqJ"},"source":["Create Custom Dataset:"]},{"cell_type":"code","metadata":{"id":"FMRDSMK4gQ7L","executionInfo":{"status":"ok","timestamp":1604527185051,"user_tz":480,"elapsed":356,"user":{"displayName":"Neil Kaushikkar","photoUrl":"","userId":"04245653301361239178"}}},"source":["import re\n","\n","class CreateDataset:\n","  def __init__(self, folder_path: str, split_ratio=(2, 1, 1)):\n","    assert len(split_ratio) == 3\n","    assert type(split_ratio) == tuple\n","    # split_ratio = (train, test, val)\n","\n","    assert type(folder_path) == str\n","    assert folder_path != None and len(folder_path) > 0\n","\n","    if folder_path[:-1] != \"/\":\n","      folder_path += \"/\"\n","\n","    self.iter_counter = 0\n","    self.split_counter = 0\n","    self.train_cut = split_ratio[0]\n","    self.test_cut = self.train_cut + split_ratio[1]\n","    self.val_cut = self.test_cut + split_ratio[2]\n","\n","    train_source = open(\"{}train.source\".format(folder_path), \"w+\")\n","    train_target = open(\"{}train.target\".format(folder_path), \"w+\")\n","    test_source = open(\"{}test.source\".format(folder_path), \"w+\")\n","    test_target = open(\"{}test.target\".format(folder_path), \"w+\")\n","    val_source = open(\"{}val.source\".format(folder_path), \"w+\")\n","    val_target = open(\"{}val.target\".format(folder_path), \"w+\")\n","\n","    self.sources = [train_source, test_source, val_source]\n","    self.targets = [train_target, test_target, val_target]\n","\n","  def create_data_files(self, data_path: str, finished=False) -> None:\n","    assert type(data_path) == str\n","    assert data_path != None and len(data_path) > 0\n","\n","    lines = self._get_prepared_lines(data_path)\n","\n","    for example in lines:\n","      if not len(example):  # ignore any emtpy text\n","        continue\n","      \n","      source, target = self._next_entry()\n","\n","      data = example.replace(\"[SEP]\", \"\")\n","      text, summary = data.split(\"[SUMM]\")\n","\n","      source.write(\"{}\\n\".format(text))\n","      target.write(\"{}\\n\".format(summary))\n","\n","    if finished:\n","      self._finish()\n","\n","  def _get_prepared_lines(self, data_path: str) -> list:\n","    text_file = open(data_path, \"r\").read()\n","    text_file = text_file.replace(\"\\n\", \"\")\n","    # strip text of all newlines, so we can control where they get places later on\n","    # newlines are used to separate entries in train/test/validation datasets\n","    text_file = re.sub(r'\\.(?=[^ ])', '. ', text_file)\n","    # replace a period followed immediately with a character with a period and a space\n","\n","    split_by_separation = text_file.split(\"[TEXT]\")\n","    \n","    return split_by_separation\n","\n","  def _finish(self) -> None:\n","    for f in self.sources:\n","      f.close()\n","    \n","    for f in self.targets:\n","      f.close()\n","      \n","  def _next_entry(self) -> tuple:\n","    if self.iter_counter == self.val_cut:\n","      self.split_counter = 0\n","      self.iter_counter = 0\n","    elif self.iter_counter == self.train_cut or self.iter_counter == self.test_cut:\n","      self.split_counter += 1\n","      \n","    self.iter_counter += 1\n","    return self.sources[self.split_counter], self.targets[self.split_counter]"],"execution_count":38,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m8Kr_Td3xzpl"},"source":["Create the text training, testing, and validation files."]},{"cell_type":"code","metadata":{"id":"1pyx3bj9xy4J","executionInfo":{"status":"ok","timestamp":1604527187488,"user_tz":480,"elapsed":465,"user":{"displayName":"Neil Kaushikkar","photoUrl":"","userId":"04245653301361239178"}},"outputId":"491c7b17-dcea-45c5-ed93-10d766382ad9","colab":{"base_uri":"https://localhost:8080/"}},"source":["%cd \"/content/drive/My Drive/CS196Project/Group6/finetuning/\"\n","\n","dataset = CreateDataset(\"lecture_transcripts/\")\n","dataset.create_data_files(\"lecture_training.txt\", finished=True)"],"execution_count":39,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/CS196Project/Group6/finetuning\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Xsda1y2kip3k"},"source":["# **Finetuning Model**"]},{"cell_type":"code","metadata":{"id":"l-q7d5k_OGxw","executionInfo":{"status":"ok","timestamp":1604527872179,"user_tz":480,"elapsed":403,"user":{"displayName":"Neil Kaushikkar","photoUrl":"","userId":"04245653301361239178"}},"outputId":"04f506a3-f5e8-4b14-f9c1-15b8cc8eafa0","colab":{"base_uri":"https://localhost:8080/"}},"source":["torch.cuda.empty_cache()\n","torch.cuda.is_available()"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"kTFtfuToiuYf"},"source":["%%bash\n","\n","cd \"/content/drive/My Drive/CS196Project/Group6/finetuning/\"\n","pwd\n","\n","# Unused Alternative Parameters:\n","    # --do_predict \\\n","    # --eval_batch_size=1 \\\n","\n","    # --freeze_embeds \\\n","    # --fp16 \\\n","\n","\n","export OUTPUT_DIR=\"example_output\"\n","export DATA_DIR=\"lecture_transcripts\"\n","\n","python seq2seq/finetune.py \\\n","    --learning_rate=3e-5 \\\n","    --gpus 1 \\\n","    --do_train \\\n","    --n_val 1000 \\\n","    --val_check_interval 0.1 \\\n","    --data_dir=$DATA_DIR \\\n","    --train_batch_size=1 \\\n","    --output_dir=$OUTPUT_DIR \\\n","    --overwrite_output_dir \\\n","    --freeze_encoder \\\n","    --num_train_epochs 6 \\\n","    --max_target_length=60 \\\n","    --val_max_target_length=60 \\\n","    --test_max_target_length=100 \\\n","    --model_name_or_path sshleifer/distilbart-xsum-12-6\n","    \"$@\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TYmkkzHU5e8V"},"source":["# **Test Model**"]},{"cell_type":"markdown","metadata":{"id":"nmw_ijOP-Pdc"},"source":["Showing that the fine-tuning has an effect: \n","\n","1.   Summarization with stored fine-tuned model\n","2.   Summarization with default model used\n","\n"]},{"cell_type":"code","metadata":{"id":"iuAratTF5igj","executionInfo":{"status":"ok","timestamp":1604528851214,"user_tz":480,"elapsed":107125,"user":{"displayName":"Neil Kaushikkar","photoUrl":"","userId":"04245653301361239178"}},"outputId":"0ef93ec4-8260-4666-fe7d-3a7f4acb5262","colab":{"base_uri":"https://localhost:8080/"}},"source":["from transformers import AutoModelForSeq2SeqLM, AutoModelWithLMHead\n","from transformers import AutoTokenizer, pipeline\n","\n","%cd \"/content/drive/My Drive/CS196Project/Group6/finetuning/\"\n","\n","device = 'cpu'\n","text = \"DNA evidence has transformed forensic science and the criminal justice system. But what are the limits of using DNA as a tool in forensic science? To address this question we need to learn the basic structure of DNA and the rules of inheritance. Let’s start by simply defining a few terms, and we’ll start with the term heredity. Heredity can simply be defined as the passing of traits to offspring. We can think about this in 2 time scales—a short time scale over just 1 generation or a long time scale involving ancestors that go back millennia. Another term that we should define is phenotype. A measurable trait of an organism is often referred to as a phenotype. Here we list examples under different categories like disease or behavioral phenotypes. We can classify phenotypes into 2 types of traits: simple inherited traits and complex inherited traits.Traits of simple inheritance have the following characteristics: They are monogenic or controlled by only 1 gene. They are binary or discontinuous. And the expression of these traits is not greatly influenced by the environment. Simple inherited traits represent only a small fraction of all human traits.\"\n","tokenizer = AutoTokenizer.from_pretrained(\"sshleifer/distilbart-xsum-12-6\") \n","\n","# 1. Summarization with fine-tuned model \n","model = AutoModelForSeq2SeqLM.from_pretrained(f'example_output/best_tfmr')\n","model = model.to(device)\n","summarizer = pipeline('summarization', model=model, tokenizer=tokenizer)\n","\n","print(summarizer(text))\n","\n","# 2. Summarization with default model used before finetuning\n","model = AutoModelWithLMHead.from_pretrained(\"sshleifer/distilbart-xsum-12-6\")\n","model.to(device)\n","summarizer = pipeline('summarization', model=model, tokenizer=tokenizer)\n","\n","print(summarizer(text))"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n","  return torch._C._cuda_getDeviceCount() > 0\n"],"name":"stderr"},{"output_type":"stream","text":["/content/drive/My Drive/CS196Project/Group6/finetuning\n","[{'summary_text': ' The use of DNA as a tool in forensic science has been hailed as a game-changer.'}]\n","[{'summary_text': ' The use of DNA as a tool in forensic science has been hailed as a game-changer.'}]\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/modeling_auto.py:825: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["[{'summary_text': 'DNA, or DNA, has been used to determine who is responsible for a crime.'}]\n"],"name":"stdout"}]}]}